{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:48:44.712278Z",
     "iopub.status.busy": "2025-11-05T06:48:44.712014Z",
     "iopub.status.idle": "2025-11-05T06:48:48.098470Z",
     "shell.execute_reply": "2025-11-05T06:48:48.097596Z",
     "shell.execute_reply.started": "2025-11-05T06:48:44.712251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qqq google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:48:48.524021Z",
     "iopub.status.busy": "2025-11-05T06:48:48.523785Z",
     "iopub.status.idle": "2025-11-05T06:48:51.858622Z",
     "shell.execute_reply": "2025-11-05T06:48:51.857592Z",
     "shell.execute_reply.started": "2025-11-05T06:48:48.524000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qqq opencv-python ultralytics numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:50:51.923210Z",
     "iopub.status.busy": "2025-11-05T06:50:51.922804Z",
     "iopub.status.idle": "2025-11-05T06:50:52.624270Z",
     "shell.execute_reply": "2025-11-05T06:50:52.623721Z",
     "shell.execute_reply.started": "2025-11-05T06:50:51.923179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:50:53.908846Z",
     "iopub.status.busy": "2025-11-05T06:50:53.908007Z",
     "iopub.status.idle": "2025-11-05T06:50:53.985854Z",
     "shell.execute_reply": "2025-11-05T06:50:53.985258Z",
     "shell.execute_reply.started": "2025-11-05T06:50:53.908818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API configured securely.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "try:\n",
    "    GEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
    "    \n",
    "    if GEMINI_API_KEY is None:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found in secrets.\")\n",
    "        \n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    print(\"‚úÖ Gemini API configured securely.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not configure Gemini API. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:50:58.098244Z",
     "iopub.status.busy": "2025-11-05T06:50:58.097578Z",
     "iopub.status.idle": "2025-11-05T06:50:58.135746Z",
     "shell.execute_reply": "2025-11-05T06:50:58.135202Z",
     "shell.execute_reply.started": "2025-11-05T06:50:58.098220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Imports for Gemini API\n",
    "import google.generativeai as genai\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:51:07.483376Z",
     "iopub.status.busy": "2025-11-05T06:51:07.482825Z",
     "iopub.status.idle": "2025-11-05T06:51:07.487393Z",
     "shell.execute_reply": "2025-11-05T06:51:07.486613Z",
     "shell.execute_reply.started": "2025-11-05T06:51:07.483334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "YOLO_MODEL_PATH = '/kaggle/input/60-epochs/60_epochs.pt'\n",
    "VIDEO_PATH = '/kaggle/input/tests-for-llm-yolo/gettyimages-1058-12-640_adpp.mp4'\n",
    "\n",
    "# Fall Detection Thresholds\n",
    "CONFIDENCE_THRESHOLD = 0.70  # YOLO confidence score to trigger LLM verification\n",
    "FALL_CLASS_ID = 0            # Based on the training output {0: 'Fall-Detected'}\n",
    "\n",
    "# LLM Cooldown\n",
    "COOLDOWN_PERIOD_SECONDS = 10 # Cooldown to prevent spamming the LLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:51:09.405909Z",
     "iopub.status.busy": "2025-11-05T06:51:09.405652Z",
     "iopub.status.idle": "2025-11-05T06:51:11.182655Z",
     "shell.execute_reply": "2025-11-05T06:51:11.181859Z",
     "shell.execute_reply.started": "2025-11-05T06:51:09.405892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ YOLOv8 Model loaded from: /kaggle/input/60-epochs/60_epochs.pt\n"
     ]
    }
   ],
   "source": [
    "LLM_PROMPT = \"\"\"\n",
    "You are an AI vision system designed to assist emergency responders. Analyze the provided image and respond ONLY in valid JSON format with the following keys:\n",
    "\n",
    "- \"fall_detected\": boolean,\n",
    "- \"context\": string (must be a 2 line description of the condition of the person and the surroundings; estimate the cause of fall as well),\n",
    "- \"bleeding_observed\": boolean,\n",
    "- \"person_condition\": string (one of: \"alert\", \"unresponsive\", \"injured\", \"bleeding\", \"unknown\"),\n",
    "- \"confidence\": float (a score in percentage (0-100)% how sure are you about your prediction in percentage)\n",
    "\n",
    "Do not include any other text.\n",
    "\"\"\"\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    fall_model = YOLO(YOLO_MODEL_PATH)\n",
    "    print(f\"‚úÖ YOLOv8 Model loaded from: {YOLO_MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load YOLO model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:51:20.111347Z",
     "iopub.status.busy": "2025-11-05T06:51:20.110210Z",
     "iopub.status.idle": "2025-11-05T06:51:20.118480Z",
     "shell.execute_reply": "2025-11-05T06:51:20.117343Z",
     "shell.execute_reply.started": "2025-11-05T06:51:20.111282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def verify_fall_with_llm(frame, prompt):\n",
    "    \"\"\"\n",
    "    Sends a frame to the Gemini LLM for high-confidence fall verification.\n",
    "    Includes diagnostic prints for debugging the hang.\n",
    "    \"\"\"\n",
    "    if 'gemini_model' not in globals():\n",
    "        print(\"LLM is not configured. Skipping verification.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "\n",
    "        # The blocking call happens here\n",
    "        response = gemini_model.generate_content([prompt, pil_image])\n",
    "\n",
    "        json_text = response.text.strip()\n",
    "\n",
    "        # Robustly strip markdown fences\n",
    "        if json_text.startswith('```json'):\n",
    "            json_text = json_text.strip().replace('```json', '').replace('```', '').strip()\n",
    "\n",
    "        return json.loads(json_text)\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå LLM JSON Decode Error: {e}\")\n",
    "        print(f\"LLM Raw Response: {response.text}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred during LLM call (Possible API Timeout): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:58:13.662785Z",
     "iopub.status.busy": "2025-11-05T06:58:13.662492Z",
     "iopub.status.idle": "2025-11-05T06:58:13.669270Z",
     "shell.execute_reply": "2025-11-05T06:58:13.668373Z",
     "shell.execute_reply.started": "2025-11-05T06:58:13.662767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def send_telegram_alert(llm_response):\n",
    "    \"\"\"\n",
    "    Formats the LLM's JSON response and sends it as a Telegram message.\n",
    "    \"\"\"\n",
    "    print(\"   Attempting to send Telegram alert...\")\n",
    "    try:\n",
    "        # Load credentials securely from secrets\n",
    "        BOT_TOKEN = user_secrets.get_secret(\"TELEGRAM_BOT_TOKEN\")\n",
    "        CHAT_ID = user_secrets.get_secret(\"TELEGRAM_CHAT_ID\")\n",
    "\n",
    "        if not BOT_TOKEN or not CHAT_ID:\n",
    "            print(\"‚ùå Telegram credentials (TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID) not found in secrets.\")\n",
    "            return\n",
    "\n",
    "        # Format the message nicely from the LLM's response\n",
    "        status = llm_response.get('person_condition', 'unknown').upper()\n",
    "        confidence = llm_response.get('confidence', 0.0)\n",
    "        context = llm_response.get('context', 'No context provided.')\n",
    "        bleeding = \"Yes\" if llm_response.get('bleeding_observed', False) else \"No\"\n",
    "\n",
    "        message_text = (\n",
    "            f\"üö® *HIGH CONFIDENCE FALL DETECTED* üö®\\n\\n\"\n",
    "            f\"*Status:* {status}\\n\"\n",
    "            f\"*Confidence:* {confidence:.2f}%\\n\"\n",
    "            f\"*Bleeding Observed:* {bleeding}\\n\\n\"\n",
    "            f\"*Context from LLM:*\\n\"\n",
    "            f\"{context}\"\n",
    "        )\n",
    "        \n",
    "        # Construct the Telegram API URL\n",
    "        url = f\"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\"\n",
    "        \n",
    "        # Create the payload\n",
    "        payload = {\n",
    "            'chat_id': CHAT_ID,\n",
    "            'text': message_text,\n",
    "            'parse_mode': 'Markdown'  # Allows for formatting (like *bold*)\n",
    "        }\n",
    "\n",
    "        # Send the request\n",
    "        response = requests.post(url, data=payload, timeout=5)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"   ‚úÖ Telegram alert sent successfully.\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Failed to send Telegram alert. Status: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå An error occurred while sending Telegram alert: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T06:58:20.629112Z",
     "iopub.status.busy": "2025-11-05T06:58:20.628633Z",
     "iopub.status.idle": "2025-11-05T06:58:50.089138Z",
     "shell.execute_reply": "2025-11-05T06:58:50.088417Z",
     "shell.execute_reply.started": "2025-11-05T06:58:20.629090Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Info: 768x432 @ 23.98 FPS, 63 frames.\n",
      "\n",
      "--- Frame 6 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "   ‚è≥ Sending frame to Gemini... (Will block until response is received)\n",
      "üö® HIGH CONFIDENCE FALL ALERT!\n",
      "   Status: UNKNOWN | Confidence: 97.50% | LLM Time: 11.76s\n",
      "   Context: A person is actively falling from a skateboard while attempting a trick on a stair handrail.\n",
      "The fall is occurring on a concrete staircase outside a building, likely due to a loss of balance during the skateboarding maneuver.\n",
      "   Attempting to send Telegram alert...\n",
      "   ‚úÖ Telegram alert sent successfully.\n",
      "----------------------------------------------------------------\n",
      "\n",
      "--- Frame 10 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "   ‚è≥ Sending frame to Gemini... (Will block until response is received)\n",
      "üö® HIGH CONFIDENCE FALL ALERT!\n",
      "   Status: ALERT | Confidence: 90.00% | LLM Time: 9.52s\n",
      "   Context: A skateboarder is in mid-air, appearing to lose balance while attempting a trick down a set of concrete stairs with railings.\n",
      "The fall is estimated to be caused by a failed attempt at a skateboarding trick or loss of balance during the maneuver.\n",
      "   Attempting to send Telegram alert...\n",
      "   ‚úÖ Telegram alert sent successfully.\n",
      "----------------------------------------------------------------\n",
      "\n",
      "--- Frame 11 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "   ‚è≥ Sending frame to Gemini... (Will block until response is received)\n",
      "‚úÖ LLM Verification: Fall not confirmed or confidence low (90.00%).\n",
      "   LLM Time: 5.78s. Context: A person is in mid-air on a skateboard, attempting a trick over a concrete barrier and stairs outdoors. The estimated cause of a potential fall would be a loss of balance or failed execution during the high-risk skateboarding maneuver.\n",
      "\n",
      "--- Frame 12 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 4.21s\n",
      "\n",
      "--- Frame 13 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 4.20s\n",
      "\n",
      "--- Frame 38 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.97s\n",
      "\n",
      "--- Frame 39 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.96s\n",
      "\n",
      "--- Frame 40 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.95s\n",
      "\n",
      "--- Frame 41 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.94s\n",
      "\n",
      "--- Frame 42 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.93s\n",
      "\n",
      "--- Frame 43 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.92s\n",
      "\n",
      "--- Frame 44 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.91s\n",
      "\n",
      "--- Frame 45 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.90s\n",
      "\n",
      "--- Frame 46 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.89s\n",
      "\n",
      "--- Frame 47 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.88s\n",
      "\n",
      "--- Frame 48 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.87s\n",
      "\n",
      "--- Frame 49 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.86s\n",
      "\n",
      "--- Frame 50 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.85s\n",
      "\n",
      "--- Frame 51 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.84s\n",
      "\n",
      "--- Frame 52 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.83s\n",
      "\n",
      "--- Frame 53 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.82s\n",
      "\n",
      "--- Frame 54 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.81s\n",
      "\n",
      "--- Frame 57 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.78s\n",
      "\n",
      "--- Frame 58 ---\n",
      "‚ö†Ô∏è YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n",
      "‚è≥ Cooldown in effect. Skipping LLM call. Remaining: 3.77s\n",
      "\n",
      "Video processing complete. üé¨\n"
     ]
    }
   ],
   "source": [
    "if not Path(VIDEO_PATH).exists():\n",
    "    print(f\"‚ùå Video file not found at: {VIDEO_PATH}\")\n",
    "elif 'fall_model' not in globals():\n",
    "    print(\"‚ùå YOLO model is not loaded. Cannot start processing.\")\n",
    "else:\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Error opening video stream or file.\")\n",
    "    else:\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        print(f\"Video Info: {frame_width}x{frame_height} @ {fps:.2f} FPS, {total_frames} frames.\")\n",
    "\n",
    "        last_llm_call_time = 0\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            current_time = time.time()\n",
    "            frame_count += 1\n",
    "\n",
    "            # --- STAGE 1: Real-Time Edge Detection (YOLOv8) ---\n",
    "            yolo_triggered = False\n",
    "            results = fall_model(frame, verbose=False)\n",
    "\n",
    "            if results and results[0].boxes:\n",
    "                for box in results[0].boxes:\n",
    "                    if int(box.cls[0]) == FALL_CLASS_ID and float(box.conf[0]) >= CONFIDENCE_THRESHOLD:\n",
    "                        yolo_triggered = True\n",
    "                        break\n",
    "\n",
    "            # If the YOLO confidence threshold is met:\n",
    "            if yolo_triggered:\n",
    "                print(f\"\\n--- Frame {frame_count} ---\")\n",
    "                print(f\"‚ö†Ô∏è YOLO Fall Detection > {CONFIDENCE_THRESHOLD*100:.2f}%! Initiating LLM Verification.\")\n",
    "\n",
    "                # --- STAGE 2: Multimodal LLM Verification (Gemini) ---\n",
    "                if current_time - last_llm_call_time >= COOLDOWN_PERIOD_SECONDS:\n",
    "\n",
    "                    llm_start_time = time.time()\n",
    "\n",
    "                    # This print statement shows we've passed the cooldown check and are entering the blocking call\n",
    "                    print(f\"   ‚è≥ Sending frame to Gemini... (Will block until response is received)\")\n",
    "                    verification_result = verify_fall_with_llm(frame, LLM_PROMPT)\n",
    "\n",
    "                    llm_duration = time.time() - llm_start_time\n",
    "\n",
    "                    if verification_result:\n",
    "                        last_llm_call_time = current_time # Update cooldown timer\n",
    "\n",
    "                        is_fall = verification_result.get('fall_detected', False)\n",
    "                        confidence = verification_result.get('confidence', 0.0)\n",
    "                        condition = verification_result.get('person_condition', 'unknown')\n",
    "                        context = verification_result.get('context', 'No context provided.')\n",
    "\n",
    "                        # Corrected Confidence Logic: LLM output (0-100) vs 80.0\n",
    "                        if is_fall and confidence >= 80.0:\n",
    "                            print(\"üö® HIGH CONFIDENCE FALL ALERT!\")\n",
    "                            print(f\"   Status: {condition.upper()} | Confidence: {confidence:.2f}% | LLM Time: {llm_duration:.2f}s\")\n",
    "                            print(f\"   Context: {context}\")\n",
    "                            send_telegram_alert(verification_result)\n",
    "                            print(\"----------------------------------------------------------------\")\n",
    "                        else:\n",
    "                            print(f\"‚úÖ LLM Verification: Fall not confirmed or confidence low ({confidence:.2f}%).\")\n",
    "                            print(f\"   LLM Time: {llm_duration:.2f}s. Context: {context}\")\n",
    "\n",
    "                    else:\n",
    "                        print(f\"LLM call failed or returned unparseable data. Duration: {llm_duration:.2f}s\")\n",
    "\n",
    "                else:\n",
    "                    cooldown_remaining = COOLDOWN_PERIOD_SECONDS - (current_time - last_llm_call_time)\n",
    "                    print(f\"‚è≥ Cooldown in effect. Skipping LLM call. Remaining: {cooldown_remaining:.2f}s\")\n",
    "\n",
    "        cap.release()\n",
    "        print(\"\\nVideo processing complete. üé¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8621388,
     "sourceId": 13571283,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8655265,
     "sourceId": 13619265,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
