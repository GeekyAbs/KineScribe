{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13571283,"sourceType":"datasetVersion","datasetId":8621388}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qqq google-genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:13:19.404788Z","iopub.execute_input":"2025-10-31T19:13:19.405016Z","iopub.status.idle":"2025-10-31T19:13:23.699938Z","shell.execute_reply.started":"2025-10-31T19:13:19.404992Z","shell.execute_reply":"2025-10-31T19:13:23.698999Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -qqq opencv-python ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:22:23.944914Z","iopub.execute_input":"2025-10-31T19:22:23.945401Z","iopub.status.idle":"2025-10-31T19:23:48.587157Z","shell.execute_reply.started":"2025-10-31T19:22:23.945376Z","shell.execute_reply":"2025-10-31T19:23:48.586480Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntransformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import google.generativeai as genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:13:23.701891Z","iopub.execute_input":"2025-10-31T19:13:23.702287Z","iopub.status.idle":"2025-10-31T19:13:25.744649Z","shell.execute_reply.started":"2025-10-31T19:13:23.702253Z","shell.execute_reply":"2025-10-31T19:13:25.743991Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"try:\n    # WARNING: Hardcoding API keys is not recommended for security.\n    # Replace 'YOUR_HARDCODED_API_KEY' with your actual API key.\n    GEMINI_API_KEY = 'AIzaSyDiDl-KQhe1eQmO_Nhje7VUDfZQRkwAku8'\n    genai.configure(api_key=GEMINI_API_KEY)\n    gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n    print(\"âœ… Gemini API configured.\")\nexcept Exception as e:\n    print(f\"âš ï¸ Could not configure Gemini API. Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:13:25.745549Z","iopub.execute_input":"2025-10-31T19:13:25.746232Z","iopub.status.idle":"2025-10-31T19:13:25.751134Z","shell.execute_reply.started":"2025-10-31T19:13:25.746202Z","shell.execute_reply":"2025-10-31T19:13:25.750443Z"}},"outputs":[{"name":"stdout","text":"âœ… Gemini API configured.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport time\nimport json\nfrom pathlib import Path\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom io import BytesIO\n\n# Imports for Gemini API\nimport google.generativeai as genai\nfrom google.colab import userdata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:21:03.265202Z","iopub.execute_input":"2025-10-31T19:21:03.265533Z","iopub.status.idle":"2025-10-31T19:21:03.539924Z","shell.execute_reply.started":"2025-10-31T19:21:03.265508Z","shell.execute_reply":"2025-10-31T19:21:03.539206Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"YOLO_MODEL_PATH = '/kaggle/input/tests-for-llm-yolo/fall_yolov8n_35epochs.pt' # Example path, update this!\nVIDEO_PATH = '/kaggle/input/tests-for-llm-yolo/gettyimages-1058-12-640_adpp.mp4' # Example video path, upload a video to test!\n\n# Fall Detection Thresholds\nCONFIDENCE_THRESHOLD = 0.70  # YOLO confidence score to trigger LLM verification\nFALL_CLASS_ID = 0            # Based on the training output {0: 'Fall-Detected'}\n\n# LLM Cooldown\nCOOLDOWN_PERIOD_SECONDS = 10 # Cooldown to prevent spamming the LLM API","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:21:45.084702Z","iopub.execute_input":"2025-10-31T19:21:45.085192Z","iopub.status.idle":"2025-10-31T19:21:45.089789Z","shell.execute_reply.started":"2025-10-31T19:21:45.085166Z","shell.execute_reply":"2025-10-31T19:21:45.089147Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"LLM_PROMPT = \"\"\"\nYou are an AI vision system designed to assist emergency responders. Analyze the provided image and respond ONLY in valid JSON format with the following keys:\n\n- \"fall_detected\": boolean,\n- \"context\": string (must be a 2 line description of the condition of the person and the surroundings; estimate the cause of fall as well),\n- \"bleeding_observed\": boolean,\n- \"person_condition\": string (one of: \"alert\", \"unresponsive\", \"injured\", \"bleeding\", \"unknown\"),\n- \"confidence\": float (a score in percentage (0-100)% how sure are you about your prediction in percentage)\n\nDo not include any other text.\n\"\"\"\ntry:\n    from ultralytics import YOLO\n    fall_model = YOLO(YOLO_MODEL_PATH)\n    print(f\"âœ… YOLOv8 Model loaded from: {YOLO_MODEL_PATH}\")\nexcept Exception as e:\n    print(f\"âŒ Failed to load YOLO model: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:26:18.348849Z","iopub.execute_input":"2025-10-31T19:26:18.349410Z","iopub.status.idle":"2025-10-31T19:26:18.522100Z","shell.execute_reply.started":"2025-10-31T19:26:18.349387Z","shell.execute_reply":"2025-10-31T19:26:18.521476Z"}},"outputs":[{"name":"stdout","text":"âœ… YOLOv8 Model loaded from: /kaggle/input/tests-for-llm-yolo/fall_yolov8n_35epochs.pt\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def verify_fall_with_llm(frame, prompt):\n    \"\"\"\n    Sends a frame to the Gemini LLM for high-confidence fall verification.\n    Includes diagnostic prints for debugging the hang.\n    \"\"\"\n    if 'gemini_model' not in globals():\n        print(\"LLM is not configured. Skipping verification.\")\n        return None\n\n    try:\n        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        pil_image = Image.fromarray(rgb_frame)\n\n        # The blocking call happens here\n        response = gemini_model.generate_content([prompt, pil_image])\n\n        json_text = response.text.strip()\n\n        # Robustly strip markdown fences\n        if json_text.startswith('```json'):\n            json_text = json_text.strip().replace('```json', '').replace('```', '').strip()\n\n        return json.loads(json_text)\n\n    except json.JSONDecodeError as e:\n        print(f\"âŒ LLM JSON Decode Error: {e}\")\n        print(f\"LLM Raw Response: {response.text}\")\n        return None\n    except Exception as e:\n        print(f\"âŒ An unexpected error occurred during LLM call (Possible API Timeout): {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:26:25.605595Z","iopub.execute_input":"2025-10-31T19:26:25.606121Z","iopub.status.idle":"2025-10-31T19:26:25.611678Z","shell.execute_reply.started":"2025-10-31T19:26:25.606097Z","shell.execute_reply":"2025-10-31T19:26:25.610667Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Main execution block\nif not Path(VIDEO_PATH).exists():\n    print(f\"âŒ Video file not found at: {VIDEO_PATH}\")\nelif 'fall_model' not in globals():\n    print(\"âŒ YOLO model is not loaded. Cannot start processing.\")\nelse:\n    cap = cv2.VideoCapture(VIDEO_PATH)\n\n    if not cap.isOpened():\n        print(\"âŒ Error opening video stream or file.\")\n    else:\n        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n        print(f\"Video Info: {frame_width}x{frame_height} @ {fps:.2f} FPS, {total_frames} frames.\")\n\n        last_llm_call_time = 0\n        frame_count = 0\n\n        while cap.isOpened():\n            ret, frame = cap.read()\n            if not ret:\n                break\n\n            current_time = time.time()\n            frame_count += 1\n\n            # --- STAGE 1: Real-Time Edge Detection (YOLOv8) ---\n            yolo_triggered = False\n            results = fall_model(frame, verbose=False)\n\n            if results and results[0].boxes:\n                for box in results[0].boxes:\n                    if int(box.cls[0]) == FALL_CLASS_ID and float(box.conf[0]) >= CONFIDENCE_THRESHOLD:\n                        yolo_triggered = True\n                        break\n\n            # If the YOLO confidence threshold is met:\n            if yolo_triggered:\n                print(f\"\\n--- Frame {frame_count} ---\")\n                print(f\"âš ï¸ YOLO Fall Detection > {CONFIDENCE_THRESHOLD*100:.2f}%! Initiating LLM Verification.\")\n\n                # --- STAGE 2: Multimodal LLM Verification (Gemini) ---\n                if current_time - last_llm_call_time >= COOLDOWN_PERIOD_SECONDS:\n\n                    llm_start_time = time.time()\n\n                    # This print statement shows we've passed the cooldown check and are entering the blocking call\n                    print(f\"   â³ Sending frame to Gemini... (Will block until response is received)\")\n                    verification_result = verify_fall_with_llm(frame, LLM_PROMPT)\n\n                    llm_duration = time.time() - llm_start_time\n\n                    if verification_result:\n                        last_llm_call_time = current_time # Update cooldown timer\n\n                        is_fall = verification_result.get('fall_detected', False)\n                        confidence = verification_result.get('confidence', 0.0)\n                        condition = verification_result.get('person_condition', 'unknown')\n                        context = verification_result.get('context', 'No context provided.')\n\n                        # Corrected Confidence Logic: LLM output (0-100) vs 80.0\n                        if is_fall and confidence >= 80.0:\n                            print(\"ğŸš¨ HIGH CONFIDENCE FALL ALERT!\")\n                            print(f\"   Status: {condition.upper()} | Confidence: {confidence:.2f}% | LLM Time: {llm_duration:.2f}s\")\n                            print(f\"   Context: {context}\")\n                            print(\"----------------------------------------------------------------\")\n                        else:\n                            print(f\"âœ… LLM Verification: Fall not confirmed or confidence low ({confidence:.2f}%).\")\n                            print(f\"   LLM Time: {llm_duration:.2f}s. Context: {context}\")\n\n                    else:\n                        print(f\"LLM call failed or returned unparseable data. Duration: {llm_duration:.2f}s\")\n\n                else:\n                    cooldown_remaining = COOLDOWN_PERIOD_SECONDS - (current_time - last_llm_call_time)\n                    print(f\"â³ Cooldown in effect. Skipping LLM call. Remaining: {cooldown_remaining:.2f}s\")\n\n        cap.release()\n        print(\"\\nVideo processing complete. ğŸ¬\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T19:26:28.477942Z","iopub.execute_input":"2025-10-31T19:26:28.478219Z","iopub.status.idle":"2025-10-31T19:26:51.431919Z","shell.execute_reply.started":"2025-10-31T19:26:28.478199Z","shell.execute_reply":"2025-10-31T19:26:51.431237Z"}},"outputs":[{"name":"stdout","text":"Video Info: 768x432 @ 23.98 FPS, 63 frames.\n\n--- Frame 38 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n   â³ Sending frame to Gemini... (Will block until response is received)\nğŸš¨ HIGH CONFIDENCE FALL ALERT!\n   Status: INJURED | Confidence: 85.00% | LLM Time: 12.54s\n   Context: The person is on the ground near the base of a staircase, lying on their back with bent legs.\nThey appear to have tripped or fallen from the stairs; another person is visible on the steps in the background.\n----------------------------------------------------------------\n\n--- Frame 40 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\n   â³ Sending frame to Gemini... (Will block until response is received)\nğŸš¨ HIGH CONFIDENCE FALL ALERT!\n   Status: INJURED | Confidence: 92.50% | LLM Time: 9.71s\n   Context: A person has fallen onto a paved outdoor surface, likely due to a skateboarding accident as a skateboard is visible nearby. They are positioned on their back/side with their legs extended upwards, indicative of a recent impact in an area with stairs and a grassy slope.\n----------------------------------------------------------------\n\n--- Frame 46 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\nâ³ Cooldown in effect. Skipping LLM call. Remaining: 0.23s\n\n--- Frame 47 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\nâ³ Cooldown in effect. Skipping LLM call. Remaining: 0.21s\n\n--- Frame 48 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\nâ³ Cooldown in effect. Skipping LLM call. Remaining: 0.20s\n\n--- Frame 49 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\nâ³ Cooldown in effect. Skipping LLM call. Remaining: 0.19s\n\n--- Frame 50 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\nâ³ Cooldown in effect. Skipping LLM call. Remaining: 0.19s\n\n--- Frame 58 ---\nâš ï¸ YOLO Fall Detection > 70.00%! Initiating LLM Verification.\nâ³ Cooldown in effect. Skipping LLM call. Remaining: 0.11s\n\nVideo processing complete. ğŸ¬\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}