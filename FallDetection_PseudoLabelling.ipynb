{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojSSYXepc2lz",
        "outputId": "e5504213-8d3d-4d40-ad74-1360e47190ce"
      },
      "outputs": [],
      "source": [
        "!pip -q install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tePSDI0Kc8wz",
        "outputId": "a84588b4-9700-4f1c-9e99-fb6f18410e58"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VLnKOHNipWP"
      },
      "outputs": [],
      "source": [
        "IMAGES_DIR = \"/content/drive/MyDrive/fall.v1i.coco/train\"\n",
        "COCO_JSON_PATH = \"/content/drive/MyDrive/fall.v1i.coco/train/_annotations.coco.json\"\n",
        "OUTPUT_LABELS_DIR = \"/content/drive/MyDrive/fall.v1i.coco\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjF2LRnqdSu2"
      },
      "outputs": [],
      "source": [
        "with open(COCO_JSON_PATH, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Build a mapping: image_id → list of ground-truth fall bounding boxes (in xywh format)\n",
        "image_id_to_bboxes = {}\n",
        "for ann in coco_data[\"annotations\"]:\n",
        "    img_id = ann[\"image_id\"]\n",
        "    # COCO bbox format: [x_min, y_min, width, height]\n",
        "    bbox = ann[\"bbox\"]\n",
        "    if img_id not in image_id_to_bboxes:\n",
        "        image_id_to_bboxes[img_id] = []\n",
        "    image_id_to_bboxes[img_id].append(bbox)\n",
        "\n",
        "# Also build image_id → file_name mapping\n",
        "image_id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in coco_data[\"images\"]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcEaC0zbfBuR",
        "outputId": "fafc65e6-cc6e-4b7c-da80-d434cdd97324"
      },
      "outputs": [],
      "source": [
        "print(\"Loading YOLOv8n-pose model...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = YOLO(\"yolov8n-pose.pt\")  # Model will auto-use GPU if available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3eUfkzajkxF"
      },
      "outputs": [],
      "source": [
        "def box_iou(box1, box2):\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "\n",
        "    xa1, ya1, xa2, ya2 = x1, y1, x1 + w1, y1 + h1\n",
        "    xb1, yb1, xb2, yb2 = x2, y2, x2 + w2, y2 + h2\n",
        "\n",
        "    inter_x1 = max(xa1, xb1)\n",
        "    inter_y1 = max(ya1, yb1)\n",
        "    inter_x2 = min(xa2, xb2)\n",
        "    inter_y2 = min(ya2, yb2)\n",
        "\n",
        "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
        "    if inter_area == 0:\n",
        "        return 0.0\n",
        "\n",
        "    area1 = w1 * h1\n",
        "    area2 = w2 * h2\n",
        "    union_area = area1 + area2 - inter_area\n",
        "\n",
        "    return inter_area / union_area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3iIUU7fjxcR",
        "outputId": "b7f51e62-5d78-4301-f23c-ab78727327b1"
      },
      "outputs": [],
      "source": [
        "print(f\"Processing {len(coco_data['images'])} images...\")\n",
        "\n",
        "for img_info in tqdm(coco_data[\"images\"], desc=\"Pseudo-labeling\"):\n",
        "    image_id = img_info[\"id\"]\n",
        "    file_name = img_info[\"file_name\"]\n",
        "    img_path = Path(IMAGES_DIR) / file_name\n",
        "\n",
        "    if not img_path.exists():\n",
        "        print(f\"⚠️  Warning: {img_path} not found. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Run inference on GPU (if available)\n",
        "    results = model(img_path, device=device, verbose=False)\n",
        "    if not results[0].boxes:\n",
        "        continue\n",
        "\n",
        "    # Move tensors to CPU only when needed for numpy conversion\n",
        "    pred_boxes = results[0].boxes.xywh.cpu().numpy()  # [xc, yc, w, h] normalized\n",
        "    pred_keypoints = results[0].keypoints.xyn.cpu().numpy()  # normalized [x, y]\n",
        "    orig_img_shape = results[0].orig_shape  # (height, width)\n",
        "\n",
        "    gt_boxes = image_id_to_bboxes.get(image_id, [])\n",
        "    label_lines = []\n",
        "\n",
        "    for i in range(len(pred_boxes)):\n",
        "        xc, yc, w, h = pred_boxes[i]\n",
        "        pred_box_abs = [\n",
        "            (xc - w / 2) * orig_img_shape[1],  # x_min\n",
        "            (yc - h / 2) * orig_img_shape[0],  # y_min\n",
        "            w * orig_img_shape[1],             # width\n",
        "            h * orig_img_shape[0]              # height\n",
        "        ]\n",
        "\n",
        "        keep = False\n",
        "        if gt_boxes:\n",
        "            for gt_box in gt_boxes:\n",
        "                iou = box_iou(pred_box_abs, gt_box)\n",
        "                if iou > 0.5:\n",
        "                    keep = True\n",
        "                    break\n",
        "        else:\n",
        "            keep = True\n",
        "\n",
        "        if not keep:\n",
        "            continue\n",
        "\n",
        "        # Keypoints are already normalized (x, y in [0,1])\n",
        "        kpts = pred_keypoints[i]\n",
        "        kpt_list = []\n",
        "        for j in range(17):\n",
        "            x, y = kpts[j]\n",
        "            vis = 2 if (0 <= x <= 1 and 0 <= y <= 1) else 0\n",
        "            kpt_list.extend([x, y, vis])\n",
        "\n",
        "        line = \"0 \" + f\"{xc:.6f} {yc:.6f} {w:.6f} {h:.6f} \" + \" \".join(f\"{kp:.6f}\" for kp in kpt_list)\n",
        "        label_lines.append(line)\n",
        "\n",
        "    # Save label file\n",
        "    label_file = Path(OUTPUT_LABELS_DIR) / (Path(file_name).stem + \".txt\")\n",
        "    with open(label_file, \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))\n",
        "\n",
        "print(\"✅ Pseudo-labeling complete!\")\n",
        "print(f\"Labels saved to: {OUTPUT_LABELS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8jB_wXUkl0X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
